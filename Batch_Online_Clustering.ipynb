{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Batch-Online Clustering.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM9+urbh+Lm2A37qt6EH5lt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bhuto1998/Online-Cluster-Validity-Index/blob/main/Batch_Online_Clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xl7_RKegokhF"
      },
      "source": [
        "# Algorithm to Update Sample Covariance Matrix:\r\n",
        "Let Sample covariance matrix be $S_{n} = \\frac{1}{n-1} \\sum_{i=1}^{n}(v_{i} - m_{n})(v_{i} - m_{n})^{T}$ where $v_{i}$'s are the datapoints and $m_{n}$ is the mean. Now let $m_{t}$ is the mean vector at time $t$. Our task is to determine the value of $S_{t+1}$ using $S_{t}$ and some key statistic. \\\\\r\n",
        "\r\n",
        " $S_{t+1} = \\frac{1}{t} \\sum_{i=1}^{t+1}(v_{i} - m_{t+1})(v_{i} - m_{t+1})^{T} = \\frac{1}{t} \\left[\\sum_{i=1}^{t}(v_{i} - m_{t+1})(v_{i} - m_{t+1})^{T} + (v_{t+1} - m_{t+1})(v_{t+1}-m_{t+1})^{T} \\right]$\r\n",
        " Let , $\\delta_{t+1} = (v_{t+1} - m_{t+1})(v_{t+1}-m_{t+1})^{T}$ and $M_{t+1} = (m_{t}-m_{t+1})(m_{t}-m_{t+1})^{T}$ \\\\\r\n",
        " Now, $(v_{i}-m_{t+1})(v_{i}-m_{t+1})^{T} = (v_{i}-m_{t}+m_{t}-m_{t+1})(v_{i}-m_{t}+m_{t}-m_{t+1})^{T} \\\\= (v_{i}-m_{t})(v_{i}-m_{t})^{T} + (v_{i}-m_{t})(m_{t}-m_{t+1})^{T} + (m_{t}-m_{t+1})(v_{i}-m_{t})^{T} + (m_{t}-m_{t+1})(m_{t}-m_{t+1})^{T}$\r\n",
        " Notice that, $\\sum_{i=1}^{t}(v_{i}-m_{t})(m_{t}-m_{t+1})^{T} = \\sum_{i=1}^{t} (m_{t}-m_{t+1})(v_{i}-m_{t})^{T} = 0$ \\\\\r\n",
        " Hence, $S_{t+1} = \\frac{1}{t}\\left[ (t-1)S_{t} + tM_{t+1} + \\delta_{t+1}  \\right]$ \r\n",
        "\r\n",
        " **Algorithm**\r\n",
        " 1. Start from $S_{2} , m_{2}$\r\n",
        " 2. For each t>2 and new data point $v_{t}$:\r\n",
        "  * $M_{t} = (m_{t-1}-m_{t})(m_{t-1}-m_{t})^{T}$\r\n",
        "  * $\\delta_{t} = (v_{t} - m_{})(v_{t}-m_{t})^{T}$ \r\n",
        "  * $S_{t} = \\frac{1}{t-1}\\left[ (t-2)S_{t-1} + (t-1)M_{t} + \\delta_{t}  \\right\r\n",
        "  ]$ \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# Batch-Online Clustering Algorithm Using Cluster Validity Index:\r\n",
        "\r\n",
        "update(a,S) function takes a new point a and sample covariance S as input and returns the updated sample covariance. ocvi(a) function takes a new point as input and add it to the existing data points and returns the optimal cluster number. $f$ is a fixed value which is the number of samples required to call a cluster \"stable\".\r\n",
        "\r\n",
        "1. For First $N$ points (typically 1000 or 2000): Find the $\\mathcal{I}^{*}$ value. Let it be $K$.\r\n",
        "2. Perform exponential fading SK-mean clustering with $\\lambda = 0.9$ and evaluate the following:\r\n",
        " * centroids/mean points of each cluster: $C_{1},...,C_{K}$\r\n",
        " * counters (number of points): $n_{1},...,n_{K}$\r\n",
        " * Covariance matrices: $S_{1},....,S_{K}$\r\n",
        " * Maximum mohalanobis distance of two points in one cluster: $maxmoha = [m_{1},...,m_{K}]$\r\n",
        "\r\n",
        "3. For each new point $x_{new}$ Perform the following: \r\n",
        " * Find out the cluster which has the minimum mohalanobis distance from this point. Let it be cluster $r$ and let that distance be $d$.\r\n",
        " *  If $d < maxmoha[r]$:\r\n",
        "    * $ p = unif(0,1)$\r\n",
        "    * If $ p > \\frac{d}{maxmoha[r]}$ or $ n_{r} < f: S_{r} = update(x_{new} , S_{r})$\r\n",
        "  * else:\r\n",
        "    * $t = ocvi(x_{new})$\r\n",
        "    * If $t==K: S_{r} = update(x_{new},S_{r})$\r\n",
        "    * Else: $C_{K+1} = x_{new}$ and $S_{K+1} = I$\r\n",
        "  * $C_{r} = \\frac{n_{r}C_{r} + x_{new}}{n_{r} + 1}$ and $n_{r} = n_{r} + 1$\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# Reasoning:\r\n",
        "In the first we wait to get a stable structure of the dataset. Note that we are using mohalanobis distance instead of regular euclidean distance to capture the deviation in terms of the distribution of the cluster and not just the cluster center. Now if the mohalanobis distance of the new point from the predicted cluster is smaller than the maximum mohalanobis distance that means it is highly likely the new point indeed belongs to the cluster and we have already seen points similar to that one. So we use it to update sample covariance probabilistically. Note that if the number of points observed for a cluster is less than a particular threshold ($f$) we say that the cluster is not yet stable (i.e. the sample covariance is not a good estimate of population covariance). Typically value of such $f$ depends on the dimension of the dataset. For univariate 35 points is good enough but for bivariate we might need more than 50 points. (This is based on large sample asymptotics of the sample covariance). In the case that the distance is larger than the maximum mohalanobis distance itself, we have a potential suspect for a new cluster itself. We run the ocvi function to check if the optimal number of cluster changed. If it did we add a new cluster and in the othercase we use that point to update the Sample covariance of the predicted cluster.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9v99MLmjZZsU"
      },
      "source": [
        "#imports\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from mpl_toolkits import mplot3d\r\n",
        "from mpl_toolkits.mplot3d import Axes3D\r\n",
        "import sklearn\r\n",
        "from sklearn.cluster import KMeans\r\n",
        "plt.rcParams[\"figure.figsize\"] = (10,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "027SWN4bZShj"
      },
      "source": [
        "#Function to update Covariance\r\n",
        "def update(x_new,S,mean_old,n):\r\n",
        "  temp = np.multiply(mean_old,n-1)\r\n",
        "  temp = np.add(temp,x_new)\r\n",
        "  mean_new = np.divide(temp,n) #evaluating updated mean\r\n",
        "\r\n",
        "  #Next we will evaluate M_t\r\n",
        "  temp = np.subtract(mean_old,mean_new)\r\n",
        "  M_t = np.outer(temp,temp)\r\n",
        "\r\n",
        "  #Evaluating delta_t\r\n",
        "  temp = np.subtract(x_new,mean_new)\r\n",
        "  delta_t = np.outer(temp,temp)\r\n",
        "\r\n",
        "  #Evaluating S_t\r\n",
        "  temp = np.multiply(M_t,n-1)\r\n",
        "  temp = np.add(temp, delta_t)\r\n",
        "  temp2 = np.multiply(S,n-2)\r\n",
        "  S_t = np.add(temp2,temp)\r\n",
        "  S_t = np.divide(S_t,n-1)\r\n",
        "\r\n",
        "  return S_t , mean_new\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_TVIjQkyJlH"
      },
      "source": [
        "#Function to find mohalanobis distance of a point from a distribution\r\n",
        "def mdist(x_new,S,m):\r\n",
        "  t = len(x_new)\r\n",
        "  temp = np.subtract(x_new,m)\r\n",
        "  S = np.linalg.inv(S)\r\n",
        "  temp2 = np.matmul(temp,S)\r\n",
        "  print(temp2)\r\n",
        "  temp3 = np.subtract(x_new,m)\r\n",
        "  temp3.shape = (t,1)\r\n",
        "  temp2 = np.matmul(temp2,temp3)\r\n",
        "  print(temp2)\r\n",
        "  temp2 = temp2 ** 0.5\r\n",
        "  return temp2[0]\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzP_Vrmj2zFX"
      },
      "source": [
        "#Some Useful Functions:\r\n",
        "#Function-1: Finding the closest cluster of a point given the point and centroids\r\n",
        "def find_closest_cluster(x, centroids):\r\n",
        "    closest_cluster, closest_distance = 999999, 999999 # initially invalid\r\n",
        "    K = len(centroids)\r\n",
        "    for k in range(K): # no. clusters\r\n",
        "        temp = 0\r\n",
        "        for j in range(len(centroids[k])):\r\n",
        "            temp = temp + (x[j]-centroids[k][j])**2\r\n",
        "        distance = temp # Euclidean distance\r\n",
        "        if distance < closest_distance:\r\n",
        "            closest_cluster  = k\r\n",
        "            closest_distance = distance\r\n",
        "    return closest_cluster\r\n",
        "\r\n",
        "#Function-2: Calculating Euclidean Norm\r\n",
        "def norm(v):\r\n",
        "    temp = 0\r\n",
        "    for i in range(len(v)):\r\n",
        "        temp = temp + (v[i]**2)\r\n",
        "    temp = temp**0.5\r\n",
        "    return temp\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1cT_Mye1H52"
      },
      "source": [
        "#OCVI value when a new datapoint arrives\r\n",
        "def E_K(x_new,l,p,g,centroids,counter):\r\n",
        "  #Evaluating E_K and E_1 \r\n",
        "  E_K = np.zeros(11)\r\n",
        "  for r in range(11):\r\n",
        "    K = r + 1\r\n",
        "    closest_K = find_closest_cluster(x_new,centroids[r])\r\n",
        "    m = counter[r].copy()\r\n",
        "    counter[r][closest_K] +=1 \r\n",
        "    temp3 = np.subtract(counter[r],m)\r\n",
        "    temp_centroids = centroids[r].copy()\r\n",
        "    temp = np.subtract(x_new,temp_centroids[closest_K])\r\n",
        "    temp = np.multiply(temp, l)\r\n",
        "    temp_centroids[closest_K] = np.add(temp_centroids[closest_K],temp)\r\n",
        "    for i in range(K):\r\n",
        "      temp1 = np.subtract(centroids[r][i],temp_centroids[i])\r\n",
        "      temp1 = np.transpose(temp1)\r\n",
        "      q = np.matmul(temp1,g[r][i])\r\n",
        "      b = norm(np.subtract(centroids[r][i],temp_centroids[i]))**2\r\n",
        "      a = temp3[i] * (norm(np.subtract(x_new,temp_centroids[i]))**2)\r\n",
        "      p[r][i] = (l*p[r][i]) + (2*q*l) + (b*m[i]*l) + a\r\n",
        "      g[r][i] = (l*g[r][i]) + np.multiply((l*m[i]),np.subtract(centroids[r][i],temp_centroids[i])) + np.multiply(temp3[i],np.subtract(x_new,temp_centroids[i]))\r\n",
        "      centroids = temp_centroids.copy()\r\n",
        "    E_K[r] = np.sum(p)\r\n",
        "    return E_K , p , g, centroids , counter\r\n",
        "def dmax(x_new,l,centroids,counter):\r\n",
        "  d = []\r\n",
        "  for r in range(1,10,1):\r\n",
        "    K = r + 2\r\n",
        "    closest_k = find_closest_cluster(x_n,centroids)\r\n",
        "    counter[r][closest_k] +=1\r\n",
        "    temp = np.subtract(x_new,centroids[r][closest_k])\r\n",
        "    temp = np.multiply(temp,l)\r\n",
        "    centroids[r][closest_k] = np.add(centroids[r][closest_k],temp)\r\n",
        "    for h in range(len(centroids[r])):\r\n",
        "      temp2 = 0\r\n",
        "      for x in range(len(centroids[r])):\r\n",
        "        v = np.linalg.norm(np.subtract(centroids[r][h],centroids[r][x]))\r\n",
        "        if v>temp2:\r\n",
        "         temp2 = v\r\n",
        "    d = d + [temp2]\r\n",
        "  return d , centroids , counter\r\n",
        "\r\n",
        "def ocvi(E_K,dmax):\r\n",
        "  o = []\r\n",
        "  for i in range(1,10,1):\r\n",
        "    t = np.divide(E_K[0],E_K[i])\r\n",
        "    d = dmax2[i-1]\r\n",
        "    t = np.multiply(t,np.multiply(d,d))\r\n",
        "    t = t/((i+1)**2)\r\n",
        "    o = o + [t]\r\n",
        "  \r\n",
        "  s = np.argmax(o)\r\n",
        "  return s+1\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_Q6WX7dEvls"
      },
      "source": [
        "def eK2(K,X,l):\r\n",
        "    if len(X)<K:\r\n",
        "        print(\"length is an issue\")\r\n",
        "    else:\r\n",
        "        centroids = X[:K]\r\n",
        "        counter = np.ones(K)\r\n",
        "        p = np.zeros(K)\r\n",
        "        temp_len = len(X) - K\r\n",
        "        eK = np.zeros(temp_len)\r\n",
        "        temp_len = (K,len(X[K]))\r\n",
        "        g = np.zeros(temp_len)\r\n",
        "        \r\n",
        "        for j in range(K,len(X),1):      \r\n",
        "            closest_K = find_closest_cluster(X[j],centroids)\r\n",
        "            m = counter.copy()\r\n",
        "            counter[closest_K] +=1\r\n",
        "            \r\n",
        "            temp3 = np.subtract(counter,m)\r\n",
        "            temp_centroids = centroids.copy()\r\n",
        "            temp = np.subtract(X[j],temp_centroids[closest_K])\r\n",
        "            temp = np.multiply(temp, l)\r\n",
        "            temp_centroids[closest_K] = np.add(temp_centroids[closest_K],temp)\r\n",
        "            #update stage\r\n",
        "            for i in range(K):\r\n",
        "                temp1 = np.subtract(centroids[i],temp_centroids[i])\r\n",
        "                temp1 = np.transpose(temp1)\r\n",
        "                q = np.matmul(temp1,g[i])\r\n",
        "                b = norm(np.subtract(centroids[i],temp_centroids[i]))**2\r\n",
        "                a = temp3[i] * (norm(np.subtract(X[j],temp_centroids[i]))**2)\r\n",
        "                p[i] = (l*p[i]) + (2*q*l) + (b*m[i]*l) + a\r\n",
        "                g[i] = (l*g[i]) + np.multiply((l*m[i]),np.subtract(centroids[i],temp_centroids[i])) + np.multiply(temp3[i],np.subtract(X[j],temp_centroids[i]))\r\n",
        "            centroids = temp_centroids.copy()\r\n",
        "            eK[j-K] = np.sum(p)\r\n",
        "        return eK, p , g , counter\r\n",
        "#Function-5: Finding d_max for exponentially fading setting\r\n",
        "def dmax2(K,X,l):\r\n",
        "    if len(X)<K:\r\n",
        "        print(\"length is an issue\")\r\n",
        "    else:\r\n",
        "        d = []\r\n",
        "        centroids = X[:K]\r\n",
        "        counter = np.ones(K)\r\n",
        "        for x_n in X[K:]:\r\n",
        "            closest_k = find_closest_cluster(x_n,centroids)\r\n",
        "            counter[closest_k] +=1\r\n",
        "            temp = np.subtract(x_n,centroids[closest_k])\r\n",
        "            temp = np.multiply(temp,l)\r\n",
        "            centroids[closest_k] = np.add(centroids[closest_k],temp)\r\n",
        "            for h in range(len(centroids)):\r\n",
        "                temp2 = 0\r\n",
        "                for x in range(len(centroids)):\r\n",
        "                    v = np.linalg.norm(np.subtract(centroids[h],centroids[x]))\r\n",
        "                    if v>temp2:\r\n",
        "                        temp2 = v\r\n",
        "            d = d + [temp2]\r\n",
        "        return d\r\n",
        "\r\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZybmHsu-4Hd"
      },
      "source": [
        "def batch_online(data,l):\r\n",
        "  num_clust = np.zeros(len(data))\r\n",
        "  #For first 2000 points we run batch clustering\r\n",
        "  X = data[:2000]\r\n",
        "  p = []\r\n",
        "  g = []\r\n",
        "  counter = [[],[],[],[],[],[],[],[],[],[],[]]\r\n",
        "  I = [[],[],[],[],[],[],[],[],[],[]]\r\n",
        "  eK1,p2,g2,counter2 = eK2(1,X,l)\r\n",
        "  for K in range(2,12,1):\r\n",
        "    d = dmax2(K,X,l)\r\n",
        "    eK,p1,g1,counter1 = eK2(K,X,l)\r\n",
        "    p = p + [p1]\r\n",
        "    g = g+ [g1]\r\n",
        "    counter[K-1] = counter[K-1] + [counter1]\r\n",
        "    \r\n",
        "    t = np.divide(eK1[(K-1):],eK)\r\n",
        "    t = np.multiply(t,np.multiply(d,d))\r\n",
        "    t = t/(K*K)\r\n",
        "    I[K]= I[K]+[t]\r\n",
        "  counter[0] = counter[0] + [counter2]\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rd79e5k3arkz",
        "outputId": "ca4ac0c0-b6dd-4a2a-a988-a0f9a5079fee"
      },
      "source": [
        "x_new = [2,3,1]\r\n",
        "S = np.eye(3)\r\n",
        "mean_old = [1,2.3,4]\r\n",
        "mdist(x_new,S,mean_old)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 1.   0.7 -3. ]\n",
            "[10.49]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.2388269481403293"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vckJplQHbXq-",
        "outputId": "29dd4bdb-c48e-47a5-8ebe-1b4bcc0959e3"
      },
      "source": [
        "norm([2,3,1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.7416573867739413"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZJrJAerfMaa",
        "outputId": "107933a6-7b47-40e5-857e-71b0ceb15dcc"
      },
      "source": [
        "mean_new"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.002 , 2.3014, 3.994 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tnnMPCAfPHA",
        "outputId": "4055703e-9417-466d-ee19-73300b9cb59c"
      },
      "source": [
        "a = np.array([3,2,1])\r\n",
        "a.shape = (3,1)\r\n",
        "a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3],\n",
              "       [2],\n",
              "       [1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpDJ6QA_zGWi",
        "outputId": "d863ccc1-e418-4145-9f8e-94467876e55c"
      },
      "source": [
        "a = np.array([3,2,1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 2, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpEUBtabzXy2",
        "outputId": "2d35de9c-a275-412f-dc58-83417e43dbe0"
      },
      "source": [
        "np.matmul([3,2,1],np.eye(3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3., 2., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OR9ratzG0tMf"
      },
      "source": [
        "p = [[1,2],[1,2,3,4],[1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSsHyUiC8KEh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "857a7444-ea6e-44f6-cdb6-577dc56957a8"
      },
      "source": [
        "t = [] \r\n",
        "r = [[1,2],[3,4]]\r\n",
        "t = t + [r]\r\n",
        "t = t + [0]\r\n",
        "t + [[[2,1],[2,3]]]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[[1, 2], [3, 4]], 0, [[2, 1], [2, 3]]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VN8C6ZIgG5wr"
      },
      "source": [
        "I = [[],[],[],[],[],[],[],[],[],[]]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2p4I9eQgI-Q9",
        "outputId": "aa1ce9eb-95e1-48ac-d2a9-34b3d66181d1"
      },
      "source": [
        "I[2] + [3]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xl_crAFiJAKJ",
        "outputId": "eb876898-228e-4963-ab65-36be940e8f90"
      },
      "source": [
        "I"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[], [], [], [], [], [], [], [], [], []]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QAuwybEJA1x",
        "outputId": "9918430c-a804-43b9-aec0-4913e6cae7de"
      },
      "source": [
        "I[2] = I[2]+ [3] + [5]\r\n",
        "I"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[], [], [3, 3, 5], [], [], [], [], [], [], []]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxIx4Ks8JEAx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}